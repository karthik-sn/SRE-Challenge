# Q4: log aggregation

## Frontend:

Front end of our application is hosted on storage account. We will enable Dignostic settings on the account and send logs to Log Analytics workspace for further storage and analysis. We will be able to query the logs in the workspace using `kusto` query language.

## Backend

All the applications on AKS should be configured to write the logs and error to `stdout` and `stderr` respectively. 

### Option1:

- Enable [****Enable Container insights](https://docs.microsoft.com/en-us/azure/azure-monitor/containers/container-insights-onboard)**
- Azure Monitor collects container logs and sends them to a Log Analytics workspace

### Option2:

- Configure log aggregator eg: fluentd to take logs from the source of all the kubernetes nodes at the path /var/log/containers/*.log.
- Add meta data using kubernetes metadata plugin https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter
- Use a streaming service to ingest the logs to Azure Log Analytics workspace

## Database

The database that is used for our scenario is Cosmos DB which has a close integration with Azure Monitor. Enable Diagnostic settings and Ship the intended logs to Log Analytics Workspace for further querying. 

## Service Bus

Similar to DB and Storage account, Service bus also can be enabled with Diagnostic settings to enable and send logs to Log Analytics workspace. 

![Untitled](Q4%20log%20aggregation%20e8630df4f3bf4e069860418139f17285/Untitled.png)